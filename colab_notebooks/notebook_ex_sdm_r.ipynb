{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Part 2: Modelling with R\"\n",
        "author: Ver√≥nica Andreo\n",
        "date: '`r Sys.Date()`'\n",
        "format: \n",
        "  html: \n",
        "    code-tools: true\n",
        "    code-copy: true\n",
        "    code-fold: false\n",
        "execute:\n",
        "  eval: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## To be run in Colab\n",
        "\n",
        "Before we start, let's install GRASS GIS, folium and mount our Drive where our GRASS project will live. We'll also install a python package to connect with R, and all needed R packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# install GRASS GIS\n",
        "!add-apt-repository -y ppa:ubuntugis/ubuntugis-unstable\n",
        "!apt update\n",
        "!apt-get install -y grass-core grass-dev\n",
        "print(\"INSTALLATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%pip install rpy2==3.5.1\n",
        "%reload_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "%R sessionInfo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "install.packages(\"rgrass\")\n",
        "install.packages(\"terra\")\n",
        "install.packages(\"raster\")\n",
        "install.packages(\"sf\")\n",
        "install.packages(\"biomod2\")\n",
        "install.packages(\"dismo\")\n",
        "install.packages(\"usdm\")\n",
        "install.packages(\"SDMtune\")\n",
        "install.packages(\"glmnet\")\n",
        "install.packages(\"zeallot\")\n",
        "install.packages(\"ggpubr\")\n",
        "install.packages(\"tmap\")\n",
        "install.packages(\"tmaptools\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Modelling with R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this third part of the workshop, we'll use R to model *Aedes albopictus*\n",
        "distribution in Northern Italy. For that, we need to connect to GRASS via\n",
        "the `rgrass` package in order to read occurrence data and predictors. The \n",
        "*rgrass* package is maintained by @rgrass and can be found at: \n",
        "<https://github.com/rsbivand/rgrass/>. See the vignette with further\n",
        "explanations and examples at: <https://rsbivand.github.io/rgrass/>.\n",
        "\n",
        "# [**rgrass**](https://cran.r-project.org/web/packages/rgrass/index.html)\n",
        "\n",
        "The basic functions we will use are:\n",
        "\n",
        "- `initGRASS()`: starts a GRASS GIS session from R\n",
        "- `execGRASS()`: executes GRASS GIS commands \n",
        "- `gmeta()`: shows GRASS project metadata\n",
        "- `read_VECT()` and `read_RAST()`: read vector and raster maps from GRASS into R *terra* objects.\n",
        "- `write_VECT()` and `write_RAST()`: write R *terra* objects into the GRASS GIS database\n",
        "\n",
        "## Usage\n",
        "\n",
        "We will start [GRASS GIS within an R session](https://grasswiki.osgeo.org/wiki/R_statistics/rgrass7#GRASS_within_R), i.e. we connect to a GRASS project from within R (or RStudio).\n",
        "The steps are as follows:\n",
        "\n",
        "- start GRASS GIS with `initGRASS()` from R\n",
        "- execute GRASS GIS tools through `execGRASS()`\n",
        "- use `read_VECT()`, `read_RAST()`, `write_VECT()` and `write_RAST()` to read data from and to GRASS database\n",
        "\n",
        "::: {.callout-note}\n",
        "`rgrass` was originally intended to apply GRASS functions on data outside GRASS projects; hence some prefer to create temporary projects.\n",
        ":::\n",
        "\n",
        "![](../assets/img/studio/grass_within_rstudio_session.png){width=\"70%\" fig-align=\"center\"}\n",
        "\n",
        "# SDM workflow\n",
        "\n",
        "In this part of the Studio we'll be covering the middle and right side of the\n",
        "SDM workflow, modeling and predictions.\n",
        "\n",
        "![](../assets/img/workflow_sdm_other.png)\n",
        "\n",
        "There are several packages to carry out SDM, in this case we'll be using\n",
        "[SDMtune](https://cloud.r-project.org/web/packages/SDMtune/index.html) by @sdmtune. It provides functions covering the whole SDM workflow, from data \n",
        "preparation, to variable selection, optimization and evaluation. Have a look\n",
        "at the articles on the package website for further details: <https://consbiol-unibern.github.io/SDMtune/index.html>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Let's move to R\n",
        "\n",
        "### Load packages needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(rgrass)\n",
        "library(sf)\n",
        "library(terra)\n",
        "library(mapview)\n",
        "library(biomod2)\n",
        "library(dismo)\n",
        "library(usdm)\n",
        "library(SDMtune)\n",
        "library(zeallot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize GRASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# path to GRASS binaries (run `grass --config path`)\n",
        "grassbin <- system(\"grass --config path\", intern = TRUE)\n",
        "# path to GRASS database\n",
        "grassdata <- path.expand(\"~/grass_ncsu_2023/grassdata/\")\n",
        "# path to location\n",
        "project <- \"eu_laea\"\n",
        "# path to mapset\n",
        "mapset <- \"italy_LST_daily\"\n",
        "\n",
        "# start GRASS GIS from R\n",
        "initGRASS(gisBase = grassbin, \n",
        "          home = tempdir(), \n",
        "          gisDbase = grassdata, \n",
        "          location = project, \n",
        "          mapset = mapset, \n",
        "          override = TRUE,\n",
        "          remove_GISRC= TRUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Read vector data\n",
        "\n",
        "Now we read in the occurrence data and the background points hosted in GRASS, convert them to `sf` objects and display them with `mapview`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read vector layers\n",
        "presence <- st_as_sf(read_VECT(\"aedes_albopictus\"))\n",
        "background <- st_as_sf(read_VECT(\"background_points\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Display vectors\n",
        "mapview(presence) + \n",
        "  mapview(background, col.regions=\"black\", cex=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Read raster data\n",
        "\n",
        "We read now all the variables that we derived from the daily LST time series.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# List rasters by pattern\n",
        "worldclim <- execGRASS(\"g.list\", \n",
        "                       parameters = list(type = \"raster\", \n",
        "                                         pattern = \"worldclim*\"))\n",
        "avg <- execGRASS(\"g.list\", \n",
        "                 parameters = list(type = \"raster\", \n",
        "                                   pattern = \"avg*\"))\n",
        "median <- execGRASS(\"g.list\", \n",
        "                    parameters = list(type = \"raster\", \n",
        "                                      pattern = \"median*\", \n",
        "                                      exclude = \"*[1-5]\"))\n",
        "\n",
        "# Concatenate map lists\n",
        "to_import <- c(attributes(worldclim)$resOut, \n",
        "               attributes(avg)$resOut, \n",
        "               attributes(median)$resOut)\n",
        "\n",
        "# Read raster layers\n",
        "predictors <- list()\n",
        "for (i in to_import){ \n",
        "  predictors[i] <- read_RAST(i) }\n",
        "\n",
        "# Stack rasters\n",
        "predictors_r <- rast(predictors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Let's visualize imported maps. Note we convert *terra* object into *raster* \n",
        "because `mapview` does not support terra yet. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Quick visualization in mapview\n",
        "mapview(raster::raster(predictors_r[['worldclim_bio01']])) + presence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preparation\n",
        "\n",
        "Now that we have imported presence records, background points and predictor\n",
        "variables derived from LST time series, we need to prepare the data in a\n",
        "format called *samples with data* (SWD). This is basically a table with presence\n",
        "and background coordinates plus the corresponding values in the predictor\n",
        "variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Variables for models\n",
        "sp <- \"Aedes albopictus\"\n",
        "presence_coords <- st_coordinates(presence)\n",
        "background <- st_coordinates(background)\n",
        "env <- predictors_r\n",
        "\n",
        "# Prepare data: SWD\n",
        "data_sp <- prepareSWD(species = sp, \n",
        "                      p = presence_coords, \n",
        "                      a = background, \n",
        "                      env = env)\n",
        "\n",
        "data_sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define relevant variables\n",
        "\n",
        "We define here some of the input values required through the workflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "seed=49\n",
        "perc_test = 0.2\n",
        "k = 4\n",
        "method=\"Maxent\"\n",
        "cor_th=0.7\n",
        "perm=10\n",
        "imp_th=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create train and test datasets\n",
        "\n",
        "We will train the model with an 80% of presence samples, and leave the remaining\n",
        "20% for evaluation at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create training and test sets\n",
        "c(train_sp, test_sp) %<-% \n",
        "  trainValTest(data_sp, \n",
        "               test = perc_test,\n",
        "               only_presence = TRUE, \n",
        "               seed = seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "test_sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create folds for cross-validation\n",
        "\n",
        "As we will use cross-validation during the model training, we create the folds\n",
        "in advance. In this case we use random folds, but other methods exist.\n",
        "Since we are limited by the number of presence records, we will create only \n",
        "4 folds. The algorithm will iteratively use 3 folds to train and 1 to validate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create folds \n",
        "ran_folds <- randomFolds(train_sp, \n",
        "                         k = k,\n",
        "                         only_presence = TRUE, \n",
        "                         seed = seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train a default Maxent model with CV\n",
        "\n",
        "We will first train a so called *full model*, i.e., a model with all predictors,\n",
        "and from there we'll remove those that are highly correlated and not so important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Train a full model\n",
        "full_model_sp <- train(method = method,\n",
        "                       data = train_sp, \n",
        "                       folds = ran_folds)\n",
        "\n",
        "full_model_sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the predictions of the full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pred_full_model <- predict(full_model_sp,\n",
        "                           data = env,\n",
        "                           type = \"cloglog\")\n",
        "\n",
        "mapview(raster::raster(pred_full_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variable selection: remove highly correlated variables \n",
        "\n",
        "We proceed then to remove correlated predictors as they provide highly redundant\n",
        "information and might affect the performance of models, i.e., as with all \n",
        "models, we want it to be simple and of the highest possible performance. We will\n",
        "use the area under the ROC curve (AUC) as the performance metric, and eliminate \n",
        "correlated variables only if AUC decreases if we keep them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Prepare background locations to test correlation\n",
        "bg_sp <- prepareSWD(species = sp, \n",
        "                    a = background,\n",
        "                    env = env)\n",
        "\n",
        "# Remove variables with correlation higher than 0.7 \n",
        "# while accounting for the AUC\n",
        "vs_sp <- varSel(full_model_sp,\n",
        "                metric = \"auc\", \n",
        "                bg4cor = bg_sp, \n",
        "                cor_th = cor_th,\n",
        "                permut = perm,\n",
        "                interactive = FALSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's explore the output object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "vs_sp@data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Remove less important variables\n",
        "\n",
        "After discarding correlated variables, we will also remove variables that have a\n",
        "percent contribution or importance lower than 10%, again accounting for AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# remove less important variables only if auc does not decrease\n",
        "reduc_var_sp <- reduceVar(vs_sp,\n",
        "                          th = imp_th, \n",
        "                          metric = \"auc\", \n",
        "                          test = TRUE, \n",
        "                          permut = perm, \n",
        "                          use_jk = TRUE,\n",
        "                          interactive = FALSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Let's explore the result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "reduc_var_sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need now to recreate the SWD object and train/test datasets, but with the \n",
        "selected variables only, in order to run the final model and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get only relevant variables from the reduced model\n",
        "retained_varnames <- names(reduc_var_sp@models[[1]]@data@data)\n",
        "\n",
        "# Subset stack\n",
        "env <- terra::subset(env, retained_varnames)\n",
        "\n",
        "# SWD with the selected vars\n",
        "subset_train_sp <- prepareSWD(species = sp, \n",
        "                              p = presence_coords,\n",
        "                              a = background,\n",
        "                              env = env)\n",
        "\n",
        "c(train_sp, test_sp) %<-% \n",
        "  trainValTest(subset_train_sp, \n",
        "               test = perc_test, \n",
        "               only_presence = TRUE, \n",
        "               seed = seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the best model and make predictions\n",
        "\n",
        "Now we train the final model with the full training set, we no longer need\n",
        "the folds at this point. Note that we also use the feature classes (fc) and\n",
        "regularization (reg) from the best model obtained before. In this case, they \n",
        "are default values only, but if we also do hyper-parameter optimization, they\n",
        "might differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "final_model_sp <- train(method = method, \n",
        "                        data = train_sp,\n",
        "                        fc = reduc_var_sp@models[[1]]@model@fc,\n",
        "                        reg = reduc_var_sp@models[[1]]@model@reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make predictions now and explore the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "map_sp_maxent <- predict(final_model_sp,\n",
        "                         data = env, \n",
        "                         type = \"cloglog\")\n",
        "\n",
        "mapview(raster::raster(map_sp_maxent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Write result back to GRASS \n",
        "\n",
        "We can now write the raster with the final model's predictions into the GRASS\n",
        "database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "write_RAST(map_sp_maxent, \n",
        "           \"Aedes_albopictus_maxent\", \n",
        "           flags = c(\"o\",\"overwrite\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the map is there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "execGRASS(\"g.list\", \n",
        "          parameters = list(type=\"raster\",\n",
        "                            pattern=\"Aedes*\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model evaluation\n",
        "\n",
        "We want to know how good our model is, so in this step we use the test dataset\n",
        "that we separated in the beginning. An AUC of 0.5 would mean the model performs\n",
        "like flipping a coin. AUC is what we call a threshold independent evaluation\n",
        "metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# AUC\n",
        "auc_maxent <- auc(final_model_sp, test = test_sp)\n",
        "auc_maxent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usually, however, the result of SDM is converted into presence/absence maps. To\n",
        "determine which threshold to use we perform threshold dependent evaluations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Threshold dependent evaluation\n",
        "th_maxent <- thresholds(final_model_sp, \n",
        "                        type = \"cloglog\", \n",
        "                        test = test_sp)\n",
        "\n",
        "knitr::kable(th_maxent, format = 'html', digits = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's choose one threshold and create a binary map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "p = map_sp_maxent >= 0.5\n",
        "a = map_sp_maxent < 0.5\n",
        "map_sp_maxent[p] <- 1\n",
        "map_sp_maxent[a] <- 0\n",
        "\n",
        "mapview(raster::raster(map_sp_maxent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variable importance\n",
        "\n",
        "Variable importance is an indicator of variable contribution to prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "vi_model_sp <- maxentVarImp(final_model_sp)\n",
        "vi_model_sp\n",
        "plotVarImp(vi_model_sp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Response curves\n",
        "\n",
        "Response curves give us an idea of the relationship between predictor variables \n",
        "and probability of occurrence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "my_rp <- function(i){\n",
        "  plotResponse(reduc_var_sp, i)\n",
        "}\n",
        "\n",
        "plotlist <- lapply(retained_varnames, my_rp)\n",
        "labels <- LETTERS[1:length(retained_varnames)]\n",
        "ggpubr::ggarrange(plotlist = plotlist, labels = labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "We close the mapset and done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# close the mapset\n",
        "unlink_.gislock()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Disclaimer\n",
        "\n",
        "This is only a simple example for doing SDM and only the beginning... \n",
        "There are:\n",
        "\n",
        "- other models to test\n",
        "- hyper-parameter tuning\n",
        "- ensemble modeling\n",
        "- uncertainty assessment: where we can predict with confidence\n",
        "- many other relevant packages: \n",
        "  - [*dismo*](https://cran.r-project.org/web/packages/dismo/index.html), [*sdm*](https://cran.r-project.org/web/packages/sdm/index.html),  [*kuenm*](https://github.com/marlonecobos/kuenm), [*caret*](https://cran.r-project.org/web/packages/caret/index.html), [*CAST*](https://cran.r-project.org/web/packages/CAST/index.html), etc.\n",
        "\n",
        "## References\n",
        "\n",
        ":::{#refs}\n",
        "\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
